Collections:
- Name: Mask2Former
  Metadata:
    Training Data:
    - Cityscapes
    - ADE20K
  Paper:
    URL: https://arxiv.org/abs/2112.01527
    Title: Masked-attention Mask Transformer for Universal Image Segmentation
  README: configs/mask2former/README.md
  Code:
    URL: https://github.com/open-mmlab/mmdetection/blob/3.x/mmdet/models/dense_heads/mask2former_head.py
    Version: 3.x
  Converted From:
    Code: https://github.com/facebookresearch/Mask2Former
Models:
- Name: mask2former_r50_8xb2-90k_cityscapes-512x1024
  In Collection: Mask2Former
  Metadata:
    backbone: R-50-D32
    crop size: (512,1024)
    lr schd: 90000
    inference time (ms/im):
    - value: 109.05
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,1024)
    Training Memory (GB): 5806.0
  Results:
  - Task: Semantic Segmentation
    Dataset: Cityscapes
    Metrics:
      mIoU: 80.16
  Config: configs/mask2former/mask2former_r50_8xb2-90k_cityscapes-512x1024.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_r50_8xb2-90k_cityscapes-512x1024/mask2former_r50_8xb2-90k_cityscapes-512x1024_20221113_021441-c9da5c95.pth
- Name: mask2former_r101_8xb2-90k_cityscapes-512x1024
  In Collection: Mask2Former
  Metadata:
    backbone: R-101-D32
    crop size: (512,1024)
    lr schd: 90000
    inference time (ms/im):
    - value: 140.65
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,1024)
    Training Memory (GB): 6971.0
  Results:
  - Task: Semantic Segmentation
    Dataset: Cityscapes
    Metrics:
      mIoU: 80.81
  Config: configs/mask2former/mask2former_r101_8xb2-90k_cityscapes-512x1024.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_r101_8xb2-90k_cityscapes-512x1024/mask2former_r101_8xb2-90k_cityscapes-512x1024_20221130_031628-8ad528ea.pth
- Name: mask2former_swin-t_8xb2-90k_cityscapes-512x1024
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-T
    crop size: (512,1024)
    lr schd: 90000
    inference time (ms/im):
    - value: 139.28
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,1024)
    Training Memory (GB): 6511.0
  Results:
  - Task: Semantic Segmentation
    Dataset: Cityscapes
    Metrics:
      mIoU: 81.71
  Config: configs/mask2former/mask2former_swin-t_8xb2-90k_cityscapes-512x1024.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-t_8xb2-90k_cityscapes-512x1024/mask2former_swin-t_8xb2-90k_cityscapes-512x1024_20221127_144501-290b34af.pth
- Name: mask2former_swin-s_8xb2-90k_cityscapes-512x1024
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-S
    crop size: (512,1024)
    lr schd: 90000
    inference time (ms/im):
    - value: 179.53
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,1024)
    Training Memory (GB): 8282.0
  Results:
  - Task: Semantic Segmentation
    Dataset: Cityscapes
    Metrics:
      mIoU: 82.57
  Config: configs/mask2former/mask2former_swin-s_8xb2-90k_cityscapes-512x1024.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-s_8xb2-90k_cityscapes-512x1024/mask2former_swin-s_8xb2-90k_cityscapes-512x1024_20221127_143802-7c98854a.pth
- Name: mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-B (in22k)
    crop size: (512,1024)
    lr schd: 90000
    inference time (ms/im):
    - value: 231.48
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,1024)
    Training Memory (GB): 11152.0
  Results:
  - Task: Semantic Segmentation
    Dataset: Cityscapes
    Metrics:
      mIoU: 83.52
  Config: configs/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-b-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221127_150026-efd13f24.pth
- Name: mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-L (in22k)
    crop size: (512,1024)
    lr schd: 90000
    inference time (ms/im):
    - value: 349.65
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,1024)
    Training Memory (GB): 16207.0
  Results:
  - Task: Semantic Segmentation
    Dataset: Cityscapes
    Metrics:
      mIoU: 83.38
  Config: configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024/mask2former_swin-l-in22k-384x384-pre_8xb2-90k_cityscapes-512x1024_20221101_105159-f285471d.pth
- Name: mask2former_r50_8xb2-160k_ade20k-512x512
  In Collection: Mask2Former
  Metadata:
    backbone: R-50-D32
    crop size: (512,512)
    lr schd: 160000
    inference time (ms/im):
    - value: 37.61
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,512)
    Training Memory (GB): 3385.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 47.22
  Config: configs/mask2former/mask2former_r50_8xb2-160k_ade20k-512x512.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_r50_8xb2-160k_ade20k-512x512/mask2former_r50_8xb2-160k_ade20k-512x512_20221116_192723-7b365f38.pth
- Name: mask2former_r101_8xb2-160k_ade20k-512x512
  In Collection: Mask2Former
  Metadata:
    backbone: R-101-D32
    crop size: (512,512)
    lr schd: 160000
    inference time (ms/im):
    - value: 43.54
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,512)
    Training Memory (GB): 4190.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 47.8
  Config: configs/mask2former/mask2former_r101_8xb2-160k_ade20k-512x512.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_r101_8xb2-160k_ade20k-512x512/mask2former_r101_8xb2-160k_ade20k-512x512_20221030_022305-9be49fd1.pth
- Name: mask2former_swin-t_8xb2-160k_ade20k-512x512
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-T
    crop size: (512,512)
    lr schd: 160000
    inference time (ms/im):
    - value: 41.98
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,512)
    Training Memory (GB): 3826.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 48.15
  Config: configs/mask2former/mask2former_swin-t_8xb2-160k_ade20k-512x512.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-t_8xb2-160k_ade20k-512x512/mask2former_swin-t_8xb2-160k_ade20k-512x512_20221113_151352-12213349.pth
- Name: mask2former_swin-s_8xb2-160k_ade20k-512x512
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-S
    crop size: (512,512)
    lr schd: 160000
    inference time (ms/im):
    - value: 50.79
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (512,512)
    Training Memory (GB): 5034.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 51.09
  Config: configs/mask2former/mask2former_swin-s_8xb2-160k_ade20k-512x512.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-s_8xb2-160k_ade20k-512x512/mask2former_swin-s_8xb2-160k_ade20k-512x512_20221117_104921-e4bab9b8.pth
- Name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_ade20k-640x640
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-B
    crop size: (640,640)
    lr schd: 160000
    inference time (ms/im):
    - value: 80.13
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (640,640)
    Training Memory (GB): 5795.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 52.44
  Config: configs/mask2former/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_ade20k-640x640.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_ade20k-640x640/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_ade20k-640x640_20221129_125118-35e3a2c7.pth
- Name: mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-B (in22k)
    crop size: (640,640)
    lr schd: 160000
    inference time (ms/im):
    - value: 80.45
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (640,640)
    Training Memory (GB): 5795.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 53.95
  Config: configs/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640/mask2former_swin-b-in22k-384x384-pre_8xb2-160k_ade20k-640x640_20221031_002811-028d15bd.pth
- Name: mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640
  In Collection: Mask2Former
  Metadata:
    backbone: Swin-L (in22k)
    crop size: (640,640)
    lr schd: 160000
    inference time (ms/im):
    - value: 113.51
      hardware: V100
      backend: PyTorch
      batch size: 1
      mode: FP32
      resolution: (640,640)
    Training Memory (GB): 9077.0
  Results:
  - Task: Semantic Segmentation
    Dataset: ADE20K
    Metrics:
      mIoU: 56.11
  Config: configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640.py
  Weights: https://download.openmmlab.com/mmsegmentation/v0.5/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640/mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640_20221030_022757-92b3a2f0.pth
